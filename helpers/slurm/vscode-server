#!/bin/bash
# This script helps run vscode-server on SLURM clusters.

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]:-$0}")" && pwd)"
source "$SCRIPT_DIR/.common.sh"
HELPER_NAME=vscode-server

# Save defaults on first run
config_init $HELPER_NAME \
    NCPUS=4 \
    MEM=16G \
    TIME=12:00:00 \
    GPU= \
    BASE_IMAGE= \
    BASE_IMAGE_DISTRO=noble \
    PORT= \
    TOKEN= \
    REUSE_MODE=ask \
    OVERLAY=env.img

# Load saved defaults
config_load $HELPER_NAME
config_require $HELPER_NAME NCPUS MEM TIME OVERLAY
# Track whether a token was set in config
if [ -z "${TOKEN:-}" ]; then AUTH_CONFIG_SET=false; else AUTH_CONFIG_SET=true; fi

print_help() {
    echo "Usage: $0 [options]"
    echo ""
    echo "Options:"
    echo "  -p <port>       Port for $HELPER_NAME (default: ${PORT:-randomly picked}). Valid range: 1024-65535"
    echo "  -a <token>      Connection token for the web UI (if empty, one is generated)"
    echo ""
    echo "  -c <number>     Number of CPUs to allocate (default: $NCPUS)"
    echo "  -m <memory>     Amount of memory to allocate (default: $MEM)"
    echo "  -t <time>       Time limit for the job (default: $TIME)"
    echo "  -g <gpu>        GPU resources (e.g., 1, a100:2). Use -g '' to clear"
    echo "  -v              View Mode NCPUS:1 MEM:4G TIME:02:00:00"
    echo "  -w              Use current directory as working directory (clears additional overlays)"
    echo ""
    echo "  -b <image>      Base image file"
    echo "  -e <.img>       Writable overlay (default: $OVERLAY)"
    echo "  -o <overlay>    Additional overlay files (can have multiple -o options)"
    echo ""
    echo "  config          Show config file path and contents"
    echo ""
    echo "State  file: $(state_path $HELPER_NAME)"
    echo "Config file: $(config_path $HELPER_NAME)"
    echo "REUSE_MODE: 'always' (auto-reuse), 'ask' (prompt, default), 'never' (always use config)"
}

case $1 in
    config)         config_show $HELPER_NAME ;;
    --help|-h|help) print_help; exit 0 ;;
    *)              ;;
esac

# show_and_connect <job_id>
#   Prints connection info and opens SSH tunnel with port forwarding.
show_and_connect() {
    local job_id="$1"
    print_info "$HELPER_NAME at ${BLUE}http://localhost:$PORT?tkn=$TOKEN&folder=$CWD${NC}"
    print_info "If you want to stop it, run: ${YELLOW}scancel $job_id${NC}"
    local local_host_long=$(hostname -f 2>/dev/null || hostname 2>/dev/null || echo "")
    local local_host_short=$(hostname -s 2>/dev/null || echo "")
    if [ "$local_host_long" != "$NODE" ] && [ "$local_host_short" != "$NODE" ]; then
        exec ssh ${SSH_OPTS} -o ControlMaster=no -L "$PORT:localhost:$PORT" "$USER@$NODE"
    fi
    exit 0
}

REUSE_PREVIOUS_CWD=false
_HAS_PREVIOUS_STATE=false
_STATE_PORT=""

STATE_FILE="$HELPER_STATE_DIR/$HELPER_NAME"
read_job_state "$STATE_FILE"
case $? in
    1) # PENDING
        print_info "Found a pending $HELPER_NAME job (ID: ${YELLOW}$JOB_ID${NC})."
        wait_for_job "$JOB_ID"
        show_and_connect "$JOB_ID"
        ;;
    2) # RUNNING
        print_info "Found an existing $HELPER_NAME job (ID: ${YELLOW}$JOB_ID${NC}) running on node ${BLUE}$NODE${NC}."
        show_and_connect "$JOB_ID"
        ;;
    3) # Not running - handle reuse after arg parse
        _HAS_PREVIOUS_STATE=true
        _STATE_PORT="${PORT:-}"
        print_info "The previous $HELPER_NAME job (ID: ${YELLOW}$JOB_ID${NC}) is no longer running."
        ;;
esac

# Track if -o flag is used to clear overlays on first use
_OVERLAYS_CLEARED=false
# Record original values for saving in state file (in case of -v option)
_NCPUS=$NCPUS
_MEM=$MEM
_TIME=$TIME
_GPU=$GPU
# Track if user wants to change working directory
NEW_CWD=""
# track whether -a supplied a token
AUTH_FLAG_SET=false

while getopts "c:m:t:g:wp:a:b:e:o:v" opt; do
    case ${opt} in
        c ) NCPUS=$OPTARG; _NCPUS=$OPTARG; _ARG_NCPUS=1 ;;
        m ) MEM=$OPTARG; _MEM=$OPTARG; _ARG_MEM=1 ;;
        t ) TIME=$OPTARG; _TIME=$OPTARG; _ARG_TIME=1 ;;
        g ) GPU=$OPTARG; _GPU=$OPTARG; _ARG_GPU=1 ;;
        v ) NCPUS=1; MEM=4G; TIME=02:00:00; _ARG_NCPUS=1; _ARG_MEM=1; _ARG_TIME=1;
            echo "[MSG] View Mode: NCPUS=1, MEM=4G, TIME=02:00:00" ;;
        w )
            NEW_CWD="$(readlink -f .)"
            if [ "$_OVERLAYS_CLEARED" = false ]; then OVERLAYS=""; _OVERLAYS_CLEARED=true; fi
            ;;
        p ) PORT=$OPTARG; _ARG_PORT=1 ;;
        a ) TOKEN=$OPTARG; AUTH_FLAG_SET=true ;;
        b ) BASE_IMAGE="$OPTARG"; _ARG_BASE_IMAGE=1 ;;
        e ) OVERLAY=$OPTARG; _ARG_OVERLAY=1 ;;
        o ) # First -o clears previous overlays, then builds fresh list
            if [ "$_OVERLAYS_CLEARED" = false ]; then OVERLAYS=""; _OVERLAYS_CLEARED=true; fi
            OVERLAYS="${OVERLAYS:+$OVERLAYS:}$OPTARG"
            ;;
        \? ) print_help; exit 1 ;;
    esac
done

# Handle reuse mode (after arg parse)
if [ "$_HAS_PREVIOUS_STATE" = true ]; then
    handle_reuse_mode "$HELPER_NAME"
fi

# Handle working directory changes
if [ -n "$NEW_CWD" ]; then
    CWD="$NEW_CWD"
elif [ "$REUSE_PREVIOUS_CWD" = true ]; then
    cd "$CWD"
fi

# Resolve port: CLI > state (reuse) > config > state
if [ -z "${_ARG_PORT:-}" ] && [ "$REUSE_PREVIOUS_CWD" != true ]; then
    if [ -n "${_CONFIG_PORT:-}" ]; then
        PORT="$_CONFIG_PORT"
    elif [ -n "$_STATE_PORT" ]; then
        PORT="$_STATE_PORT"
    fi
fi

# Show settings before job submission (once)
if [ "$_SPECS_SHOWN" != true ]; then
    print_msg "Using settings:"
    print_specs
    countdown 3
fi

# If no port specified, pick an available one
if [ -z "$PORT" ]; then
    PORT=$(choose_port) || {
        print_error "Failed to find an available port. Please specify one with -p."
        exit 1
    }
    print_info "Available port :${BLUE}$PORT${NC} auto-selected."
    print_info "Remember to set up port forwarding: ${CYAN}ssh -L $PORT:localhost:$PORT $USER@login-node${NC}"
    if ! confirm_default_yes "Proceed with this port?"; then
        echo "Aborted by user."; exit 1
    fi
else
    validate_port "$PORT"
fi

#region Sanity Checks
check_port_available "$PORT"
check_condatainer

# Ensure VSCode CLI
CODE_BIN="$HOME/.local/bin/code"
if ! [ -f "$CODE_BIN" ]; then
    print_info "VSCode CLI not found. Downloading..."
    ARCH=$(uname -m)
    if [ "$ARCH" == "x86_64" ]; then ARCH="linux-x64"; elif [ "$ARCH" == "aarch64" ]; then ARCH="linux-arm64"; else
        print_error "Unsupported architecture: $ARCH"
        exit 1
    fi
    wget -nv -O vscode-cli.tar.gz "https://update.code.visualstudio.com/latest/cli-$ARCH/stable"
    mkdir -p "$(dirname "$CODE_BIN")"
    tar -xzf vscode-cli.tar.gz -C "$(dirname "$CODE_BIN")" code && rm vscode-cli.tar.gz
    chmod +x "$CODE_BIN"
else
    print_info "Updating VSCode CLI..."
    [ -x "$CODE_BIN" ] && "$CODE_BIN" update >/dev/null 2>&1
fi

check_and_install_overlays $OVERLAYS

if [ ! -f "$OVERLAY" ]; then
    print_warn "Overlay ${BLUE}$OVERLAY${NC} not found. Continuing without it."
    countdown 3
else
    check_overlay_integrity "$OVERLAY"
fi
#endregion

# Construct arguments for CondaTainer exec
[ -n "$BASE_IMAGE" ] && BASE_IMAGE_ARG="-b $BASE_IMAGE"
[ -n "$OVERLAY" ] && [ -f "$OVERLAY" ] && OVERLAY_ARG="-o $OVERLAY"
[ -n "$OVERLAYS" ] && OVERLAYS_ARG=$(build_overlays_arg "$OVERLAYS")
# Parse GPU input (supports '1', 'h100:2', '2:h100') for SLURM --gres=gpu format
if [ -n "$GPU" ]; then
    if [[ "$GPU" == *":"* ]]; then
        PART1="${GPU%:*}"
        PART2="${GPU#*:}"
        if [[ "$PART1" =~ ^[0-9]+$ ]]; then
            # Format: 2:h100 → h100:2
            GPU_SBATCH="#SBATCH --gres=gpu:${PART2}:${PART1}"
        else
            # Format: h100:2 → h100:2
            GPU_SBATCH="#SBATCH --gres=gpu:${PART1}:${PART2}"
        fi
    else
        # Format: 2 → 2
        GPU_SBATCH="#SBATCH --gres=gpu:$GPU"
    fi
fi

# Generate a random token if not provided by config or -a
if [ "${AUTH_FLAG_SET:-false}" = "false" ] && [ "${AUTH_CONFIG_SET:-false}" = "false" ]; then
    print_info "No connection token provided. Generating a random one..."
    TOKEN=$(openssl rand -hex 8 2>/dev/null || tr -dc 'a-zA-Z0-9' </dev/urandom | head -c 16 || echo "$(date +%s)-$RANDOM")
fi

SBATCH_SCRIPT_PATH="$LOG_DIR/$HELPER_NAME.sbatch"

cat <<EOT > "$SBATCH_SCRIPT_PATH"
#!/bin/bash
#SBATCH --job-name=$HELPER_NAME
#SBATCH --cpus-per-task=$NCPUS
#SBATCH --mem=$MEM
#SBATCH --time=$TIME
${GPU_SBATCH:+$GPU_SBATCH}
#SBATCH --output=$LOG_DIR/$HELPER_NAME-%j.log

while ! grep -q "^JOB_ID=" "$STATE_FILE" 2>/dev/null; do sleep 1; done
echo "NODE=\$(hostname)" >> "$STATE_FILE"

condatainer exec \
    $BASE_IMAGE_ARG \
    $OVERLAYS_ARG \
    $OVERLAY_ARG --writable \
    $CODE_BIN serve-web \
        --port $PORT \
        --accept-server-license-terms \
        --connection-token $TOKEN
EOT

rm -f "$STATE_FILE"
SBATCH_OUTPUT=$(sbatch "$SBATCH_SCRIPT_PATH")
SBATCH_JOB_ID=$(echo $SBATCH_OUTPUT | awk '{print $4}')

cat > "$STATE_FILE" <<RUNSTATE
JOB_ID=$SBATCH_JOB_ID
NCPUS=$_NCPUS
MEM=$_MEM
TIME=$_TIME
GPU=$_GPU
PORT=$PORT
CWD=$CWD
TOKEN=$TOKEN
BASE_IMAGE="$BASE_IMAGE"
OVERLAY="$OVERLAY"
OVERLAYS="$OVERLAYS"
RUNSTATE

wait_for_job "$SBATCH_JOB_ID"
rm -f "$SBATCH_SCRIPT_PATH" # Clean up on success
show_and_connect "$SBATCH_JOB_ID"
